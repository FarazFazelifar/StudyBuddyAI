{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StudyBuddyAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StudyBuddy AI is an intelligent learning assistant that leverages advanced AI technologies to enhance the studying experience. It uses a sophisticated Retrieval-Augmented Generation (RAG) system to provide personalized answers and generate topic-specific flashcards based on your study materials.\n",
    "\n",
    "Features\n",
    "- Document Processing: Ingest and process PDF study materials.\n",
    "- Intelligent Q&A: Get accurate answers to questions about your study material.\n",
    "- Dynamic Flashcard Generation: Create custom flashcards on any topic within your documents.\n",
    "- RAG Technology: Utilizes state-of-the-art Retrieval-Augmented Generation for context-aware responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG\n",
    "If you don't know what RAG (Retrieval Augmented Generation) is, you can follow my [RAG tutorial](https://github.com/FarazFazelifar/RAG-Demo1) to learn and understand what RAG is and implement one from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0: Setting Up\n",
    "As always, we start by importing our requiered packages. You can install them by running `pip install -r requierments.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: StudyBuddyAI\n",
    "StudyBuddy AI is an intelligent learning companion that leverages state-of-the-art AI technologies to enhance the studying experience. At its core, StudyBuddy AI utilizes a sophisticated Retrieval-Augmented Generation (RAG) system. It leverages RAG to answer questions and also generate flashcards. I am using llama3.1 as the LLM and the all-MiniLM model as the embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AdvancedStudyBuddyAI:\n",
    "    def __init__(self, pdf_directory: str, db_path: str = \"studybuddy_vectordb\"):\n",
    "        self.pdf_directory = pdf_directory\n",
    "        self.db_path = db_path\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        self.vectorstore = None\n",
    "        self.qa_chain = None\n",
    "        self.llm = Ollama(model=\"llama3.1\", temperature=0.2)\n",
    "\n",
    "    def load_and_process_pdfs(self):\n",
    "        documents = []\n",
    "        for filename in os.listdir(self.pdf_directory):\n",
    "            if filename.endswith('.pdf'):\n",
    "                file_path = os.path.join(self.pdf_directory, filename)\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                documents.extend(loader.load())\n",
    "\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "        self.vectorstore = FAISS.from_documents(chunks, self.embeddings)\n",
    "        self.vectorstore.save_local(self.db_path)\n",
    "        print(f\"Processed and saved {len(chunks)} chunks from {len(documents)} documents.\")\n",
    "\n",
    "    def load_vectorstore(self):\n",
    "        if os.path.exists(self.db_path):\n",
    "            self.vectorstore = FAISS.load_local(self.db_path, self.embeddings, allow_dangerous_deserialization=True)\n",
    "            print(\"Vector database loaded successfully.\")\n",
    "        else:\n",
    "            print(\"No existing vector database found. Please process PDFs first.\")\n",
    "\n",
    "    def setup_qa_chain(self):\n",
    "        if self.vectorstore is None:\n",
    "            print(\"Please load or process documents before setting up the QA chain.\")\n",
    "            return\n",
    "\n",
    "        retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "        self.qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True\n",
    "        )\n",
    "\n",
    "    def query(self, question: str) -> Dict:\n",
    "        if self.qa_chain is None:\n",
    "            print(\"Please set up the QA chain before querying.\")\n",
    "            return {\"answer\": \"QA chain not set up\", \"sources\": []}\n",
    "\n",
    "        result = self.qa_chain({\"query\": question})\n",
    "        return {\n",
    "            \"answer\": result['result'],\n",
    "            \"sources\": [doc.page_content for doc in result['source_documents']]\n",
    "        }\n",
    "\n",
    "    def generate_and_save_flashcards(self, topic: str, num_cards: int):\n",
    "        if self.vectorstore is None:\n",
    "            print(\"Please load or process documents before generating flashcards.\")\n",
    "            return\n",
    "\n",
    "        # Retrieve relevant chunks based on the topic\n",
    "        relevant_chunks = self.vectorstore.similarity_search(topic, k=num_cards)\n",
    "        \n",
    "        flashcards = []\n",
    "        for chunk in relevant_chunks:\n",
    "            content = chunk.page_content\n",
    "            flashcard_prompt = (\n",
    "                f\"Based on the following content about '{topic}', generate a flashcard with a question and answer:\\n\\n\"\n",
    "                f\"{content}\\n\\n\"\n",
    "                f\"Format the response as JSON with 'question' and 'answer' keys. \"\n",
    "                f\"Ensure the question and answer are directly related to the topic '{topic}'.\"\n",
    "            )\n",
    "            \n",
    "            response = self.llm(flashcard_prompt)\n",
    "            try:\n",
    "                flashcard = json.loads(response)\n",
    "                flashcards.append(flashcard)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Failed to parse flashcard JSON: {response}\")\n",
    "\n",
    "        # Save flashcards to a text file\n",
    "        if not os.path.exists(\"flashcards\"):\n",
    "            os.makedirs(\"flashcards\")\n",
    "        \n",
    "        filename = os.path.join(\"flashcards\", f\"{topic.replace(' ', '_')}.txt\")\n",
    "        with open(filename, \"w\") as f:\n",
    "            for i, card in enumerate(flashcards, 1):\n",
    "                f.write(f\"Flashcard {i}:\\n\")\n",
    "                f.write(f\"Q: {card['question']}\\n\")\n",
    "                f.write(f\"A: {card['answer']}\\n\\n\")\n",
    "        \n",
    "        print(f\"Generated and saved {len(flashcards)} flashcards on the topic '{topic}' to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_state(studybuddy: AdvancedStudyBuddyAI, filename: str = \"advanced_studybuddy_state.pkl\"):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(studybuddy, f)\n",
    "    print(f\"State saved to {filename}\")\n",
    "\n",
    "def load_state(filename: str = \"advanced_studybuddy_state.pkl\") -> AdvancedStudyBuddyAI:\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    return AdvancedStudyBuddyAI(\"documents/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Running the main program\n",
    "After loading the state and creating our AdvancedStudyBuddyAI instance, we can run the program and use it to enhance our learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studybuddy = load_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(\"\\nStudyBuddy AI - Main Menu\")\n",
    "    print(\"1. Process PDF Documents\")\n",
    "    print(\"2. Load Vector Database\")\n",
    "    print(\"3. Setup QA Chain\")\n",
    "    print(\"4. Ask a Question\")\n",
    "    print(\"5. Generate Flashcards\")\n",
    "    print(\"6. Quit\")\n",
    "\n",
    "    choice = input(\"Enter your choice (1-6): \")\n",
    "\n",
    "    if choice == \"1\":\n",
    "        studybuddy.load_and_process_pdfs()\n",
    "    elif choice == \"2\":\n",
    "        studybuddy.load_vectorstore()\n",
    "    elif choice == \"3\":\n",
    "        studybuddy.setup_qa_chain()\n",
    "    elif choice == \"4\":\n",
    "        question = input(\"Enter your question: \")\n",
    "        result = studybuddy.query(question)\n",
    "        print(f\"Answer: {result['answer']}\")\n",
    "        print(\"\\nSources:\")\n",
    "        for i, source in enumerate(result['sources'], 1):\n",
    "            print(f\"{i}. {source[:200]}...\")\n",
    "    elif choice == \"5\":\n",
    "        topic = input(\"Enter the topic for the flashcards: \")\n",
    "        num_cards = int(input(\"How many flashcards do you want to generate? \"))\n",
    "        studybuddy.generate_and_save_flashcards(topic, num_cards)\n",
    "    elif choice == \"6\":\n",
    "        print(\"Thank you for using Advanced StudyBuddy AI. Goodbye!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid choice. Please try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
